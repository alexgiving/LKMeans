{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import root\n",
    "import time\n",
    "\n",
    "\n",
    "def minkowski_distance(point_a: np.ndarray, point_b: np.ndarray, p: float) -> np.ndarray:\n",
    "    '''\n",
    "    Minkowski distance function.\n",
    "    '''\n",
    "    absolute_difference = np.abs(point_a - point_b)\n",
    "    power_in_sum = np.power(absolute_difference, p)\n",
    "    summa = np.sum(power_in_sum)\n",
    "    return np.power(summa, 1/p)\n",
    "\n",
    "\n",
    "def minkowski_loss(cluster: np.ndarray, centroid: np.ndarray, p: float) -> np.ndarray:\n",
    "    '''\n",
    "    SGD Minkowski Loss function.\n",
    "    Return the coordinate sum of the Minkowski differences\n",
    "    Formula: [âˆ‘_j (xji - ci)^p]\n",
    "    '''\n",
    "    loss = []\n",
    "    for point in cluster:\n",
    "        absolute_difference = np.abs(point - centroid)\n",
    "        power_in_sum = np.power(absolute_difference, p)\n",
    "        loss.append(power_in_sum)\n",
    "    loss = np.array(loss)\n",
    "    dim_loss = np.sum(loss, axis=0)\n",
    "    return dim_loss\n",
    "\n",
    "\n",
    "def minkowski_1_derivative(parameter_to_solve: np.ndarray, cluster: np.ndarray, p: float):\n",
    "    return np.sum([np.sign(point-parameter_to_solve)*np.abs(point-parameter_to_solve)**(p-1) for point in cluster], axis=0)\n",
    "\n",
    "\n",
    "class KMeans:\n",
    "    def __init__(self, n_clusters, max_iter=100, p=2):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "        self.p = p\n",
    "        self.centroids = []\n",
    "        self.labels = []\n",
    "\n",
    "    def fit(self, X):\n",
    "        # initialize centroids randomly\n",
    "        self.centroids = [X[i] for i in np.random.choice(X.shape[0], self.n_clusters, replace=False)]\n",
    "\n",
    "        for _ in range(self.max_iter):\n",
    "            clusters = [[] for _ in range(self.n_clusters)]\n",
    "            self.labels = []\n",
    "\n",
    "            # assign each data point to the closest centroid\n",
    "            for x in X:\n",
    "                distances_to_each_cebtroid = [minkowski_distance(x, centroid, self.p) for centroid in self.centroids]\n",
    "                closest_centroid = np.argmin(distances_to_each_cebtroid)\n",
    "                clusters[closest_centroid].append(x)\n",
    "                self.labels.append(closest_centroid)\n",
    "\n",
    "            # update centroids using the specified optimizer\n",
    "            for cluster_id, cluster in enumerate(clusters):\n",
    "                cluster = np.array(cluster)\n",
    "                if len(cluster) == 0:\n",
    "                    continue\n",
    "                if self.p == 2:\n",
    "                    self.centroids[cluster_id] = np.mean(cluster, axis=0)\n",
    "                elif self.p == 1:\n",
    "                    self.centroids[cluster_id] = np.median(cluster, axis=0)\n",
    "                elif self.p > 1:\n",
    "                    '''\n",
    "                    SGD optimizer\n",
    "                    Amorim, Renato. (2012). Feature Weighting for Clustering: Using K-Means and the Minkowski Metric. \n",
    "                    '''\n",
    "                    learning_rate = 0.01\n",
    "                    grad_descent = 0.1\n",
    "                    n_iters = 50\n",
    "                    centroid = np.mean(cluster, axis=0)\n",
    "\n",
    "                    for sgd_iteration in range(n_iters):\n",
    "                        if sgd_iteration == n_iters / 2:\n",
    "                            learning_rate *= grad_descent\n",
    "                        loss = minkowski_loss(cluster, centroid, self.p)\n",
    "                        grad = np.gradient(loss, axis=0)\n",
    "                        centroid -= learning_rate * grad\n",
    "                    self.centroids[cluster_id] = centroid\n",
    "                elif 0 < self.p < 1:\n",
    "                    '''\n",
    "                    Find extremum of minkowski function by root of 1 derivative.\n",
    "                    '''\n",
    "                    sol = root(minkowski_1_derivative, np.mean(cluster, axis=0), args=(cluster, self.p), method='hybr')\n",
    "                    self.centroids[cluster_id] = sol.x\n",
    "                else:\n",
    "                    raise ValueError(f'Unsupported value of p: {self.p}')\n",
    "                    # if self.optimizer == 'SLSQP':\n",
    "                    #     bounds = [(None, None)] * self.centroids[j].shape[0]\n",
    "                    #     self.centroids[j] = minimize(\n",
    "                    #         lambda x: minkowski_distance(x, cluster, self.p),\n",
    "                    #         self.centroids[j].flatten(),\n",
    "                    #         method=self.optimizer,\n",
    "                    #         bounds=bounds\n",
    "                    #     ).x.copy()\n",
    "                    # elif self.optimizer in ('Powell', 'CG', 'BFGS', 'L-BFGS-B', 'TNC', 'COBYLA', 'trust-constr'):\n",
    "                    #     self.centroids[j] = minimize(lambda x: minkowski_distance(x, cluster, self.p), self.centroids[j], method=self.optimizer).x.copy()\n",
    "\n",
    "        return self.centroids, self.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Optional\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.metrics import adjusted_mutual_info_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def generate_gaussian_clusters(\n",
    "    centroid_locations: List[List],\n",
    "    sigma: float,\n",
    "    dimension: int,\n",
    "    n_points_per_cluster: int = 100\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "\n",
    "    clusters = []\n",
    "    labels = []\n",
    "    randomizer = np.random.default_rng()\n",
    "\n",
    "    for cluster_id, centroid_location in enumerate(centroid_locations):\n",
    "        cluster_size = (n_points_per_cluster, dimension)\n",
    "        labels_size = (n_points_per_cluster, )\n",
    "\n",
    "        cluster_points = randomizer.normal(\n",
    "            loc=centroid_location,\n",
    "            scale=sigma,\n",
    "            size=cluster_size\n",
    "        )\n",
    "\n",
    "        cluster_labels = np.full(shape=labels_size, fill_value=cluster_id)\n",
    "\n",
    "        clusters.append(cluster_points)\n",
    "        labels.append(cluster_labels)\n",
    "\n",
    "    return np.concatenate(clusters), np.concatenate(labels)\n",
    "\n",
    "\n",
    "def generate_cluster_centroids(\n",
    "    dimension: int,\n",
    "    n_clusters: int,\n",
    "    distance_factor: float\n",
    "    ) -> np.ndarray:\n",
    "\n",
    "    centroid_locations = np.stack([np.random.random(dimension) * distance_factor for _ in range(n_clusters)])\n",
    "    return centroid_locations\n",
    "\n",
    "\n",
    "def get_one_experiment_metrics(\n",
    "    true_labels: List,\n",
    "    pred_labels: List,\n",
    "    p: Optional[float] = None,\n",
    "    time: Optional[float] = None) -> pd.DataFrame:\n",
    "\n",
    "    ari = adjusted_rand_score(true_labels, pred_labels)\n",
    "    ami = adjusted_mutual_info_score(true_labels, pred_labels)\n",
    "\n",
    "    data = {'Adjusted Rand Index': ari, 'Adjusted Mutual Information': ami}\n",
    "    if time:\n",
    "        data['Time'] = time\n",
    "    index = [f'Experiment with p: {p}'] if p else [f'Experiment'] \n",
    "    frame = pd.DataFrame(data, index)\n",
    "    return frame\n",
    "\n",
    "\n",
    "def get_average_experiment_metrics(\n",
    "    ari: List,\n",
    "    ami: List,\n",
    "    p: Optional[float] = None,\n",
    "    time: Optional[float] = None) -> pd.DataFrame:\n",
    "\n",
    "    data = {'ARI': f'{np.mean(ari):.2f}', 'AMI': f'{np.mean(ami):.2f}'}\n",
    "    if time:\n",
    "        data['Time'] = f'{np.mean(time):.2f}'\n",
    "    index = [f'Experiment (p = {p})'] if p else [f'Experiment'] \n",
    "    frame = pd.DataFrame(data, index)\n",
    "    return frame\n",
    "\n",
    "\n",
    "class MetricTable:\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.frames = []\n",
    "\n",
    "    def add_frame(self, frame: pd.DataFrame) -> None:\n",
    "        self.frames.append(frame)\n",
    "\n",
    "    def get_table(self) -> pd.DataFrame:\n",
    "        return pd.concat(self.frames, join=\"inner\")\n",
    "\n",
    "    def get_latex_table(self, caption: str = '') -> str:\n",
    "        table = self.get_table()\n",
    "        return table.to_latex(index=True, escape=True, caption=caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "def print_clusters(clusters: np.ndarray,\n",
    "                   labels: np.ndarray,\n",
    "                   centroids: Optional[np.ndarray] = None) -> None:\n",
    "\n",
    "    color_map = {0: 'red', 1: 'green', 2: 'blue', 3: 'yellow', 4: 'purple'}\n",
    "\n",
    "    colors = [color_map[label] for label in labels]\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "\n",
    "    if not isinstance(centroids, type(None)):\n",
    "        concuted = np.concatenate((clusters, np.array(centroids)), axis=0)\n",
    "        clusters_tsne = tsne.fit_transform(concuted)\n",
    "\n",
    "        plt.scatter(clusters_tsne[:-len(centroids),0], clusters_tsne[:-len(centroids),1], c=colors)\n",
    "        plt.scatter(clusters_tsne[-len(centroids):,0], clusters_tsne[-len(centroids):,1], marker='*', s=100, c='black')\n",
    "    else:\n",
    "        clusters_tsne = tsne.fit_transform(clusters)\n",
    "        plt.scatter(clusters_tsne[:,0], clusters_tsne[:,1], c=colors)\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1\n",
    "---\n",
    "Dimension: 2\n",
    "\n",
    "Number of clusters: 2\n",
    "\n",
    "Distance factor between centroids: [0.1, 0.2, ..., 0.9]\n",
    "\n",
    "Parameter: [0.2, 0.5, 1, 2, 3]\n",
    "\n",
    "Number of repeats: 100\n",
    "\n",
    "Points: [100, 500, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/87/3cnclgy53jd11fkzc4qp7mlc0000gn/T/ipykernel_11405/393703879.py:27: RuntimeWarning: overflow encountered in power\n",
      "  power_in_sum = np.power(absolute_difference, p)\n",
      "/Users/alexgiving/Documents/diploma/venv/lib/python3.10/site-packages/numpy/lib/function_base.py:1236: RuntimeWarning: invalid value encountered in subtract\n",
      "  out[tuple(slice1)] = (f[tuple(slice4)] - f[tuple(slice2)]) / (2. * ax_dx)\n",
      "/Users/alexgiving/Documents/diploma/venv/lib/python3.10/site-packages/numpy/lib/function_base.py:1257: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  out[tuple(slice1)] = (f[tuple(slice2)] - f[tuple(slice3)]) / dx_0\n",
      "/Users/alexgiving/Documents/diploma/venv/lib/python3.10/site-packages/numpy/lib/function_base.py:1264: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  out[tuple(slice1)] = (f[tuple(slice2)] - f[tuple(slice3)]) / dx_n\n",
      "/var/folders/87/3cnclgy53jd11fkzc4qp7mlc0000gn/T/ipykernel_11405/393703879.py:27: RuntimeWarning: overflow encountered in power\n",
      "  power_in_sum = np.power(absolute_difference, p)\n",
      "/Users/alexgiving/Documents/diploma/venv/lib/python3.10/site-packages/numpy/lib/function_base.py:1236: RuntimeWarning: invalid value encountered in subtract\n",
      "  out[tuple(slice1)] = (f[tuple(slice4)] - f[tuple(slice2)]) / (2. * ax_dx)\n",
      "/Users/alexgiving/Documents/diploma/venv/lib/python3.10/site-packages/numpy/lib/function_base.py:1257: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  out[tuple(slice1)] = (f[tuple(slice2)] - f[tuple(slice3)]) / dx_0\n",
      "/Users/alexgiving/Documents/diploma/venv/lib/python3.10/site-packages/numpy/lib/function_base.py:1264: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  out[tuple(slice1)] = (f[tuple(slice2)] - f[tuple(slice3)]) / dx_n\n",
      "/var/folders/87/3cnclgy53jd11fkzc4qp7mlc0000gn/T/ipykernel_11405/393703879.py:27: RuntimeWarning: overflow encountered in power\n",
      "  power_in_sum = np.power(absolute_difference, p)\n",
      "/Users/alexgiving/Documents/diploma/venv/lib/python3.10/site-packages/numpy/lib/function_base.py:1236: RuntimeWarning: invalid value encountered in subtract\n",
      "  out[tuple(slice1)] = (f[tuple(slice4)] - f[tuple(slice2)]) / (2. * ax_dx)\n",
      "/Users/alexgiving/Documents/diploma/venv/lib/python3.10/site-packages/numpy/lib/function_base.py:1257: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  out[tuple(slice1)] = (f[tuple(slice2)] - f[tuple(slice3)]) / dx_0\n",
      "/Users/alexgiving/Documents/diploma/venv/lib/python3.10/site-packages/numpy/lib/function_base.py:1264: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  out[tuple(slice1)] = (f[tuple(slice2)] - f[tuple(slice3)]) / dx_n\n",
      "/Users/alexgiving/Documents/diploma/venv/lib/python3.10/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/var/folders/87/3cnclgy53jd11fkzc4qp7mlc0000gn/T/ipykernel_11405/393703879.py:27: RuntimeWarning: overflow encountered in power\n",
      "  power_in_sum = np.power(absolute_difference, p)\n",
      "/Users/alexgiving/Documents/diploma/venv/lib/python3.10/site-packages/numpy/lib/function_base.py:1236: RuntimeWarning: invalid value encountered in subtract\n",
      "  out[tuple(slice1)] = (f[tuple(slice4)] - f[tuple(slice2)]) / (2. * ax_dx)\n",
      "/Users/alexgiving/Documents/diploma/venv/lib/python3.10/site-packages/numpy/lib/function_base.py:1264: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  out[tuple(slice1)] = (f[tuple(slice2)] - f[tuple(slice3)]) / dx_n\n",
      "/Users/alexgiving/Documents/diploma/venv/lib/python3.10/site-packages/numpy/lib/function_base.py:1257: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  out[tuple(slice1)] = (f[tuple(slice2)] - f[tuple(slice3)]) / dx_0\n",
      "/Users/alexgiving/Documents/diploma/venv/lib/python3.10/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/var/folders/87/3cnclgy53jd11fkzc4qp7mlc0000gn/T/ipykernel_11405/393703879.py:27: RuntimeWarning: overflow encountered in power\n",
      "  power_in_sum = np.power(absolute_difference, p)\n",
      "/Users/alexgiving/Documents/diploma/venv/lib/python3.10/site-packages/numpy/lib/function_base.py:1236: RuntimeWarning: invalid value encountered in subtract\n",
      "  out[tuple(slice1)] = (f[tuple(slice4)] - f[tuple(slice2)]) / (2. * ax_dx)\n",
      "/Users/alexgiving/Documents/diploma/venv/lib/python3.10/site-packages/numpy/lib/function_base.py:1257: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  out[tuple(slice1)] = (f[tuple(slice2)] - f[tuple(slice3)]) / dx_0\n",
      "/Users/alexgiving/Documents/diploma/venv/lib/python3.10/site-packages/numpy/lib/function_base.py:1264: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  out[tuple(slice1)] = (f[tuple(slice2)] - f[tuple(slice3)]) / dx_n\n",
      "/var/folders/87/3cnclgy53jd11fkzc4qp7mlc0000gn/T/ipykernel_11405/393703879.py:27: RuntimeWarning: overflow encountered in power\n",
      "  power_in_sum = np.power(absolute_difference, p)\n",
      "/Users/alexgiving/Documents/diploma/venv/lib/python3.10/site-packages/numpy/lib/function_base.py:1236: RuntimeWarning: invalid value encountered in subtract\n",
      "  out[tuple(slice1)] = (f[tuple(slice4)] - f[tuple(slice2)]) / (2. * ax_dx)\n",
      "/Users/alexgiving/Documents/diploma/venv/lib/python3.10/site-packages/numpy/lib/function_base.py:1257: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  out[tuple(slice1)] = (f[tuple(slice2)] - f[tuple(slice3)]) / dx_0\n",
      "/Users/alexgiving/Documents/diploma/venv/lib/python3.10/site-packages/numpy/lib/function_base.py:1264: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  out[tuple(slice1)] = (f[tuple(slice2)] - f[tuple(slice3)]) / dx_n\n",
      "/var/folders/87/3cnclgy53jd11fkzc4qp7mlc0000gn/T/ipykernel_11405/393703879.py:27: RuntimeWarning: overflow encountered in power\n",
      "  power_in_sum = np.power(absolute_difference, p)\n",
      "/Users/alexgiving/Documents/diploma/venv/lib/python3.10/site-packages/numpy/lib/function_base.py:1236: RuntimeWarning: invalid value encountered in subtract\n",
      "  out[tuple(slice1)] = (f[tuple(slice4)] - f[tuple(slice2)]) / (2. * ax_dx)\n",
      "/Users/alexgiving/Documents/diploma/venv/lib/python3.10/site-packages/numpy/lib/function_base.py:1257: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  out[tuple(slice1)] = (f[tuple(slice2)] - f[tuple(slice3)]) / dx_0\n",
      "/Users/alexgiving/Documents/diploma/venv/lib/python3.10/site-packages/numpy/lib/function_base.py:1264: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  out[tuple(slice1)] = (f[tuple(slice2)] - f[tuple(slice3)]) / dx_n\n",
      "/var/folders/87/3cnclgy53jd11fkzc4qp7mlc0000gn/T/ipykernel_11405/393703879.py:27: RuntimeWarning: overflow encountered in power\n",
      "  power_in_sum = np.power(absolute_difference, p)\n",
      "/Users/alexgiving/Documents/diploma/venv/lib/python3.10/site-packages/numpy/lib/function_base.py:1236: RuntimeWarning: invalid value encountered in subtract\n",
      "  out[tuple(slice1)] = (f[tuple(slice4)] - f[tuple(slice2)]) / (2. * ax_dx)\n",
      "/Users/alexgiving/Documents/diploma/venv/lib/python3.10/site-packages/numpy/lib/function_base.py:1257: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  out[tuple(slice1)] = (f[tuple(slice2)] - f[tuple(slice3)]) / dx_0\n",
      "/Users/alexgiving/Documents/diploma/venv/lib/python3.10/site-packages/numpy/lib/function_base.py:1264: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  out[tuple(slice1)] = (f[tuple(slice2)] - f[tuple(slice3)]) / dx_n\n",
      "/var/folders/87/3cnclgy53jd11fkzc4qp7mlc0000gn/T/ipykernel_11405/393703879.py:27: RuntimeWarning: overflow encountered in power\n",
      "  power_in_sum = np.power(absolute_difference, p)\n",
      "/Users/alexgiving/Documents/diploma/venv/lib/python3.10/site-packages/numpy/lib/function_base.py:1236: RuntimeWarning: invalid value encountered in subtract\n",
      "  out[tuple(slice1)] = (f[tuple(slice4)] - f[tuple(slice2)]) / (2. * ax_dx)\n",
      "/Users/alexgiving/Documents/diploma/venv/lib/python3.10/site-packages/numpy/lib/function_base.py:1257: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  out[tuple(slice1)] = (f[tuple(slice2)] - f[tuple(slice3)]) / dx_0\n",
      "/Users/alexgiving/Documents/diploma/venv/lib/python3.10/site-packages/numpy/lib/function_base.py:1264: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  out[tuple(slice1)] = (f[tuple(slice2)] - f[tuple(slice3)]) / dx_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 1 with distance factor 0.1 \\begin{table}\n",
      "\\centering\n",
      "\\caption{Experiment 1 with distance factor 0.1}\n",
      "\\begin{tabular}{llll}\n",
      "\\toprule\n",
      "{} &   ARI &   AMI &    Time \\\\\n",
      "\\midrule\n",
      "Experiment (p = 2)   &  0.91 &  0.85 &    1.88 \\\\\n",
      "Experiment (p = 1)   &  0.56 &  0.46 &    1.92 \\\\\n",
      "Experiment (p = 0.5) &  0.68 &  0.57 &  105.63 \\\\\n",
      "Experiment (p = 0.2) &  0.72 &  0.62 &   37.18 \\\\\n",
      "Experiment (p = 3)   &  0.84 &  0.75 &   19.59 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dimension = 20 # dimensionality\n",
    "n_clusters = 2 # Number of clusters\n",
    "sigma = 1 # STD distribution\n",
    "n_points_per_cluster = 500\n",
    "repeats = 1\n",
    "\n",
    "path_data = Path('experiments') / f'experiment_sigma_{sigma}'\n",
    "path_data.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "\n",
    "for distance_factor in np.arange(0.1, 1., 0.1):\n",
    "\n",
    "    metrics = MetricTable()\n",
    "    for p in [2, 1, 0.5, 0.2, 3]:\n",
    "\n",
    "        repeats_ari = []\n",
    "        repeats_ami = []\n",
    "        repeats_time = []\n",
    "\n",
    "        for repeat in range(repeats):\n",
    "\n",
    "            centroid = generate_cluster_centroids(\n",
    "                dimension=dimension,\n",
    "                n_clusters=n_clusters,\n",
    "                distance_factor=distance_factor\n",
    "            )\n",
    "\n",
    "            clusters, labels = generate_gaussian_clusters(\n",
    "                dimension=dimension,\n",
    "                sigma=sigma,\n",
    "                centroid_locations=centroid,\n",
    "                n_points_per_cluster=n_points_per_cluster\n",
    "            )\n",
    "\n",
    "            experiment_time = time.perf_counter()\n",
    "            kmeans = KMeans(n_clusters=n_clusters, p=p)\n",
    "            generated_centroids, generated_labels = kmeans.fit(clusters)\n",
    "\n",
    "            repeats_time.append(time.perf_counter()-experiment_time)\n",
    "            repeats_ari.append(adjusted_rand_score(labels, generated_labels))\n",
    "            repeats_ami.append(adjusted_mutual_info_score(labels, generated_labels))\n",
    "\n",
    "            frame = get_average_experiment_metrics(repeats_ari, repeats_ami, p, time=repeats_time)\n",
    "        metrics.add_frame(frame)\n",
    "        # print_clusters(clusters, generated_labels, generated_centroids)\n",
    "    table_name = f'Experiment 1 with distance factor {distance_factor:.1f}'\n",
    "    table = metrics.get_latex_table(caption=table_name)\n",
    "\n",
    "    latex_logs = path_data / (f'factor_{distance_factor:.1f}'.replace('.', '_') + '.tex')\n",
    "    latex_logs.touch(exist_ok=True)\n",
    "    with latex_logs.open('w') as f:\n",
    "        f.write(table)\n",
    "    print(table_name, table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
