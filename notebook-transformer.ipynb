{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "def minkowski_distance(a, b, p):\n",
    "    difference = np.subtract(a, b)\n",
    "    absolute_difference = np.abs(difference)\n",
    "    power_in_sum = np.power(absolute_difference, p)\n",
    "    summa = np.sum(power_in_sum)\n",
    "    return np.power(summa, 1/p)\n",
    "\n",
    "\n",
    "# def minkowski_distance(x, y, p):\n",
    "#     if len(x) != len(y):\n",
    "#         raise ValueError(\"Vectors x and y must have the same length\")\n",
    "#     return = np.power(np.sum(np.power(np.abs(x - y), p)), 1/p)\n",
    "\n",
    "# def minkowski_distance(x, y, p):\n",
    "#     \"\"\"Calculate the Minkowski distance between two points.\"\"\"\n",
    "#     return np.sum(np.abs(x - y) ** p) ** (1 / p)\n",
    "\n",
    "\n",
    "class KMeans:\n",
    "    def __init__(self, n_clusters, max_iter=100, p=2, optimizer='mean'):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "        self.p = p\n",
    "        self.optimizer = optimizer\n",
    "        self.centroids = []\n",
    "        self.labels = []\n",
    "\n",
    "    def fit(self, X):\n",
    "        # initialize centroids randomly\n",
    "        self.centroids = [X[i] for i in np.random.choice(X.shape[0], self.n_clusters, replace=False)]\n",
    "\n",
    "        for _ in range(self.max_iter):\n",
    "            clusters = [[] for _ in range(self.n_clusters)]\n",
    "            self.labels = []\n",
    "\n",
    "            # assign each data point to the closest centroid\n",
    "            for x in X:\n",
    "                distances_to_each_cebtroid = [minkowski_distance(x, centroid, self.p) for centroid in self.centroids]\n",
    "                closest_centroid = np.argmin(distances_to_each_cebtroid)\n",
    "                clusters[closest_centroid].append(x)\n",
    "                self.labels.append(closest_centroid)\n",
    "\n",
    "            # update centroids using the specified optimizer\n",
    "            for j, cluster in enumerate(clusters):\n",
    "                cluster = np.array(cluster)\n",
    "                if len(cluster) == 0:\n",
    "                    continue\n",
    "                if self.optimizer == 'mean':\n",
    "                    self.centroids[j] = cluster.mean(axis=0)\n",
    "                elif self.optimizer == 'median':\n",
    "                    self.centroids[j] = np.median(cluster, axis=0)\n",
    "                elif self.optimizer in ('Powell', 'CG', 'BFGS', 'L-BFGS-B', 'TNC', 'COBYLA', 'SLSQP', 'trust-constr'):\n",
    "                    self.centroids[j] = minimize(lambda x: minkowski_distance(x, cluster, self.p), self.centroids[j], method=self.optimizer).x.copy()\n",
    "                else:\n",
    "                    raise ValueError(f\"Unsupported optimizer: {self.optimizer}\")\n",
    "\n",
    "        return self.centroids, self.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_clusters(k, means, stds, n_points_per_cluster, X, distance_factor=1):\n",
    "    clusters = []\n",
    "    labels = []\n",
    "    for i in range(k):\n",
    "        mean, std = means[i] * distance_factor, stds[i]\n",
    "        cov = np.identity(X) * std ** 2\n",
    "        points = np.random.multivariate_normal(mean, cov, n_points_per_cluster)\n",
    "        clusters.append(points)\n",
    "        labels.append(np.full((n_points_per_cluster,), i))\n",
    "    return np.concatenate(clusters), np.concatenate(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def make_plots(axs, index, color_map, data, labels, opt_name=''):\n",
    "    colors = [color_map[label] for label in labels]\n",
    "\n",
    "    tsne = TSNE(n_components=2)\n",
    "    data_2d = tsne.fit_transform(data)\n",
    "\n",
    "    axs[index, 0].scatter(data_2d[:,0], data_2d[:,1], c=colors)\n",
    "    # axs[index, 0].set_xlabel('t-SNE Dimension 1')\n",
    "    # axs[index, 0].set_ylabel('t-SNE Dimension 2')\n",
    "    axs[index, 0].set_title(f'{opt_name} in 2D via t-SNE')\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    data_2d = pca.fit_transform(data)\n",
    "\n",
    "    axs[index, 1].scatter(data_2d[:,0], data_2d[:,1], c=colors)\n",
    "    # axs[index, 1].set_xlabel('PCA Dimension 1')\n",
    "    # axs[index, 1].set_ylabel('PCA Dimension 2')\n",
    "    axs[index, 1].set_title(f'{opt_name} in 2D via PCA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 2\n",
    "assert n_clusters <= 5, \"n_clusters must be less than or equal to 5\"\n",
    "\n",
    "\n",
    "color_map = {0: 'red', 1: 'green', 2: 'blue', 3: 'yellow', 4: 'purple'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 50\n",
    "means = [np.zeros(dimension), np.ones(dimension), -np.ones(dimension), np.ones(dimension) * -1 + 1, np.ones(dimension) + -1]\n",
    "stds = [0.5, 0.5, 0.5, 0.5, 0.5]\n",
    "n_points_per_cluster = 100\n",
    "distance_factor = 0.3\n",
    "\n",
    "data, true_labels = generate_clusters(n_clusters, means, stds, n_points_per_cluster, dimension, distance_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data\n",
    "optimizers = ['mean', 'median', 'Powell', 'CG', 'BFGS', 'L-BFGS-B', 'TNC', 'COBYLA', 'SLSQP', 'trust-constr']\n",
    "data_map = dict.fromkeys(optimizers)\n",
    "p = 0.2\n",
    "\n",
    "len_optimizers = len(optimizers)\n",
    "fig, axs = plt.subplots(len_optimizers, 2, figsize=(15, 5*len_optimizers))\n",
    "fig.suptitle(f'Experiment with data dim: {dimension}, p: {p}', fontsize=16)\n",
    "\n",
    "for index, optimizer in enumerate(optimizers):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, optimizer=optimizer, p=p)\n",
    "    centroids, labels = kmeans.fit(X)\n",
    "    data_map[optimizer] = labels\n",
    "\n",
    "    make_plots(axs, index, color_map, X, labels, optimizer)\n",
    "    print(f'Processed {optimizer}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.metrics import mutual_info_score\n",
    "import pandas as pd\n",
    "\n",
    "ari = []\n",
    "ami = []\n",
    "for optimizer in optimizers:\n",
    "    pred_lable = data_map[optimizer]\n",
    "    ari.append(adjusted_rand_score(true_labels, pred_lable))\n",
    "    ami.append(mutual_info_score(true_labels, pred_lable))\n",
    "\n",
    "pd.DataFrame({'Adjusted Rand Index': ari, 'Mutual Information Score': ami}, index=optimizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "36104695effaec50923a999bb05887f92dc015032090d1611399610c41417c01"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
